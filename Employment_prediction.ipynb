{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMooQvPorFtAUqzyeT+UhJJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joy-Terer/BSE-05-0254/blob/main/Employment_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWzbIct9T_GK"
      },
      "outputs": [],
      "source": [
        "# TASK 1: DATA LOADING AND EXPLORATION\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set visualization style\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"EMPLOYMENT PREDICTION USING DECISION TREE CLASSIFIER\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Load the IBM HR Analytics Attrition Dataset\n",
        "# Download from: https://www.kaggle.com/datasets/pavansubhasht/ibm-hr-analytics-attritiondataset\n",
        "print(\"\\n[1] LOADING IBM HR ANALYTICS DATASET...\")\n",
        "try:\n",
        "    # Try common file names for this dataset\n",
        "    try:\n",
        "        df_original = pd.read_csv('WA_Fn-UseC_-HR-Employee-Attrition.csv')\n",
        "    except:\n",
        "        df_original = pd.read_csv('HR-Employee-Attrition.csv')\n",
        "\n",
        "    print(\"✓ IBM HR Dataset loaded successfully!\")\n",
        "    print(f\"   Original dataset shape: {df_original.shape}\")\n",
        "\n",
        "    # Map IBM HR dataset to assignment requirements\n",
        "    print(\"\\n[2] MAPPING IBM HR DATASET TO ASSIGNMENT REQUIREMENTS...\")\n",
        "\n",
        "    # Create the required columns based on IBM HR data\n",
        "    df = pd.DataFrame()\n",
        "\n",
        "    # age - Direct mapping\n",
        "    df['age'] = df_original['Age']\n",
        "\n",
        "    # education_level - Map Education (1-5) to education levels\n",
        "    education_mapping = {\n",
        "        1: 'High School',\n",
        "        2: 'Bachelor',\n",
        "        3: 'Bachelor',\n",
        "        4: 'Master',\n",
        "        5: 'PhD'\n",
        "    }\n",
        "    df['education_level'] = df_original['Education'].map(education_mapping)\n",
        "\n",
        "    # years_of_experience - Use TotalWorkingYears\n",
        "    df['years_of_experience'] = df_original['TotalWorkingYears']\n",
        "\n",
        "    # technical_test_score - Simulate using PercentSalaryHike and PerformanceRating\n",
        "    # Scale to 0-100\n",
        "    df['technical_test_score'] = (\n",
        "        (df_original['PercentSalaryHike'] * 3) +\n",
        "        (df_original['PerformanceRating'] * 15)\n",
        "    ).clip(40, 100)\n",
        "\n",
        "    # interview_score - Simulate using JobSatisfaction and EnvironmentSatisfaction\n",
        "    # Scale to 0-10\n",
        "    df['interview_score'] = (\n",
        "        (df_original['JobSatisfaction'] + df_original['EnvironmentSatisfaction']) * 1.25\n",
        "    ).clip(3, 10).round(1)\n",
        "\n",
        "    # previous_employment - Use NumCompaniesWorked (0 = No, >0 = Yes)\n",
        "    df['previous_employment'] = df_original['NumCompaniesWorked'].apply(\n",
        "        lambda x: 'Yes' if x > 0 else 'No'\n",
        "    )\n",
        "\n",
        "    # suitable_for_employment - Inverse of Attrition (No Attrition = Suitable)\n",
        "    df['suitable_for_employment'] = df_original['Attrition'].apply(\n",
        "        lambda x: 'No' if x == 'Yes' else 'Yes'\n",
        "    )\n",
        "\n",
        "    print(\"✓ Dataset mapped successfully!\")\n",
        "    print(f\"   Mapped features: {', '.join(df.columns)}\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"⚠ IBM HR Dataset file not found!\")\n",
        "    print(\"   Please download from: https://www.kaggle.com/datasets/pavansubhasht/ibm-hr-analytics-attritiondataset\")\n",
        "    print(\"   Expected filename: 'WA_Fn-UseC_-HR-Employee-Attrition.csv'\")\n",
        "    print(\"\\n   Creating sample data for demonstration...\")\n",
        "\n",
        "    # Create sample dataset based on assignment description\n",
        "    np.random.seed(42)\n",
        "    n_samples = 500\n",
        "    df = pd.DataFrame({\n",
        "        'age': np.random.randint(22, 60, n_samples),\n",
        "        'education_level': np.random.choice(['High School', 'Bachelor', 'Master', 'PhD'], n_samples),\n",
        "        'years_of_experience': np.random.randint(0, 30, n_samples),\n",
        "        'technical_test_score': np.random.randint(40, 100, n_samples),\n",
        "        'interview_score': np.random.uniform(3, 10, n_samples).round(1),\n",
        "        'previous_employment': np.random.choice(['Yes', 'No'], n_samples),\n",
        "        'suitable_for_employment': np.random.choice(['Yes', 'No'], n_samples, p=[0.6, 0.4])\n",
        "    })\n",
        "    print(\"✓ Sample dataset created!\")\n",
        "\n",
        "# Display first few rows\n",
        "print(\"\\n[2] DATASET PREVIEW:\")\n",
        "print(df.head(10))\n",
        "\n",
        "# Dataset Information\n",
        "print(\"\\n[3] DATASET INFORMATION:\")\n",
        "print(f\"Shape: {df.shape[0]} rows × {df.shape[1]} columns\")\n",
        "print(\"\\nColumn Details:\")\n",
        "print(df.info())\n",
        "\n",
        "# Basic Statistics\n",
        "print(\"\\n[4] STATISTICAL SUMMARY:\")\n",
        "print(df.describe())\n",
        "\n",
        "# Check for null values\n",
        "print(\"\\n[5] MISSING VALUES CHECK:\")\n",
        "null_counts = df.isnull().sum()\n",
        "print(null_counts)\n",
        "if null_counts.sum() == 0:\n",
        "    print(\"✓ No missing values found!\")\n",
        "else:\n",
        "    print(\"⚠ Missing values detected. Handling required.\")\n",
        "\n",
        "# Distribution of target variable\n",
        "print(\"\\n[6] TARGET VARIABLE DISTRIBUTION:\")\n",
        "target_dist = df['suitable_for_employment'].value_counts()\n",
        "print(target_dist)\n",
        "print(f\"\\nClass Balance: {target_dist.values[0]/target_dist.sum()*100:.1f}% vs {target_dist.values[1]/target_dist.sum()*100:.1f}%\")\n",
        "\n",
        "# =============================================================================\n",
        "# EXPLORATORY DATA ANALYSIS (EDA)\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"EXPLORATORY DATA ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Visualizations\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "fig.suptitle('Exploratory Data Analysis - Feature Distributions', fontsize=16, y=1.02)\n",
        "\n",
        "# Age distribution\n",
        "axes[0, 0].hist(df['age'], bins=20, color='skyblue', edgecolor='black')\n",
        "axes[0, 0].set_title('Age Distribution')\n",
        "axes[0, 0].set_xlabel('Age')\n",
        "axes[0, 0].set_ylabel('Frequency')\n",
        "\n",
        "# Education level\n",
        "df['education_level'].value_counts().plot(kind='bar', ax=axes[0, 1], color='lightcoral')\n",
        "axes[0, 1].set_title('Education Level Distribution')\n",
        "axes[0, 1].set_xlabel('Education Level')\n",
        "axes[0, 1].set_ylabel('Count')\n",
        "axes[0, 1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Years of experience\n",
        "axes[0, 2].hist(df['years_of_experience'], bins=15, color='lightgreen', edgecolor='black')\n",
        "axes[0, 2].set_title('Years of Experience Distribution')\n",
        "axes[0, 2].set_xlabel('Years')\n",
        "axes[0, 2].set_ylabel('Frequency')\n",
        "\n",
        "# Technical test score\n",
        "axes[1, 0].hist(df['technical_test_score'], bins=20, color='gold', edgecolor='black')\n",
        "axes[1, 0].set_title('Technical Test Score Distribution')\n",
        "axes[1, 0].set_xlabel('Score')\n",
        "axes[1, 0].set_ylabel('Frequency')\n",
        "\n",
        "# Interview score\n",
        "axes[1, 1].hist(df['interview_score'], bins=15, color='plum', edgecolor='black')\n",
        "axes[1, 1].set_title('Interview Score Distribution')\n",
        "axes[1, 1].set_xlabel('Score')\n",
        "axes[1, 1].set_ylabel('Frequency')\n",
        "\n",
        "# Target variable\n",
        "df['suitable_for_employment'].value_counts().plot(kind='bar', ax=axes[1, 2], color=['green', 'red'])\n",
        "axes[1, 2].set_title('Suitability for Employment')\n",
        "axes[1, 2].set_xlabel('Suitable')\n",
        "axes[1, 2].set_ylabel('Count')\n",
        "axes[1, 2].tick_params(axis='x', rotation=0)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('eda_distributions.png', dpi=300, bbox_inches='tight')\n",
        "print(\"\\n✓ EDA visualizations saved as 'eda_distributions.png'\")\n",
        "\n",
        "# =============================================================================\n",
        "# TASK 2: DATA PREPROCESSING\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"DATA PREPROCESSING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Create a copy for preprocessing\n",
        "df_processed = df.copy()\n",
        "\n",
        "# Encode categorical variables\n",
        "print(\"\\n[1] ENCODING CATEGORICAL VARIABLES...\")\n",
        "\n",
        "# Label Encoding for binary variables\n",
        "le_prev_emp = LabelEncoder()\n",
        "df_processed['previous_employment'] = le_prev_emp.fit_transform(df_processed['previous_employment'])\n",
        "print(f\"   Previous Employment: {dict(zip(le_prev_emp.classes_, le_prev_emp.transform(le_prev_emp.classes_)))}\")\n",
        "\n",
        "# Target variable encoding\n",
        "le_target = LabelEncoder()\n",
        "df_processed['suitable_for_employment'] = le_target.fit_transform(df_processed['suitable_for_employment'])\n",
        "print(f\"   Target Variable: {dict(zip(le_target.classes_, le_target.transform(le_target.classes_)))}\")\n",
        "\n",
        "# One-hot encoding for education level\n",
        "df_processed = pd.get_dummies(df_processed, columns=['education_level'], prefix='edu')\n",
        "print(f\"   Education Level: One-hot encoded into {len([col for col in df_processed.columns if col.startswith('edu_')])} columns\")\n",
        "\n",
        "print(\"\\n[2] PROCESSED DATASET:\")\n",
        "print(df_processed.head())\n",
        "\n",
        "# Split features and target\n",
        "X = df_processed.drop('suitable_for_employment', axis=1)\n",
        "y = df_processed['suitable_for_employment']\n",
        "\n",
        "print(f\"\\n[3] FEATURE MATRIX SHAPE: {X.shape}\")\n",
        "print(f\"    Target VECTOR SHAPE: {y.shape}\")\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"\\n[4] DATA SPLIT COMPLETE:\")\n",
        "print(f\"    Training Set: {X_train.shape[0]} samples ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
        "print(f\"    Testing Set:  {X_test.shape[0]} samples ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
        "\n",
        "# =============================================================================\n",
        "# TASK 3: MODEL BUILDING\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"MODEL BUILDING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Train Decision Tree Classifier\n",
        "print(\"\\n[1] TRAINING DECISION TREE CLASSIFIER...\")\n",
        "dt_classifier = DecisionTreeClassifier(\n",
        "    criterion='gini',\n",
        "    max_depth=5,\n",
        "    min_samples_split=10,\n",
        "    min_samples_leaf=5,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "dt_classifier.fit(X_train, y_train)\n",
        "print(\"✓ Model training complete!\")\n",
        "\n",
        "print(f\"\\n[2] MODEL PARAMETERS:\")\n",
        "print(f\"    Criterion: {dt_classifier.criterion}\")\n",
        "print(f\"    Max Depth: {dt_classifier.max_depth}\")\n",
        "print(f\"    Min Samples Split: {dt_classifier.min_samples_split}\")\n",
        "print(f\"    Min Samples Leaf: {dt_classifier.min_samples_leaf}\")\n",
        "print(f\"    Number of Features: {dt_classifier.n_features_in_}\")\n",
        "print(f\"    Number of Classes: {dt_classifier.n_classes_}\")\n",
        "\n",
        "# =============================================================================\n",
        "# TASK 4: MODEL VISUALIZATION\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"MODEL VISUALIZATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Visualize decision tree\n",
        "plt.figure(figsize=(20, 12))\n",
        "plot_tree(\n",
        "    dt_classifier,\n",
        "    feature_names=X.columns,\n",
        "    class_names=['Not Suitable', 'Suitable'],\n",
        "    filled=True,\n",
        "    rounded=True,\n",
        "    fontsize=10\n",
        ")\n",
        "plt.title('Decision Tree for Employment Prediction', fontsize=16, pad=20)\n",
        "plt.savefig('decision_tree_visualization.png', dpi=300, bbox_inches='tight')\n",
        "print(\"\\n✓ Decision tree visualization saved as 'decision_tree_visualization.png'\")\n",
        "\n",
        "# =============================================================================\n",
        "# TASK 5: MODEL TESTING AND PREDICTION\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"MODEL TESTING AND PREDICTION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Predictions on test set\n",
        "y_pred = dt_classifier.predict(X_test)\n",
        "print(f\"\\n[1] PREDICTIONS ON TEST SET COMPLETE\")\n",
        "print(f\"    Total predictions: {len(y_pred)}\")\n",
        "\n",
        "# Test with 3 hypothetical candidates\n",
        "print(\"\\n[2] TESTING WITH HYPOTHETICAL CANDIDATES:\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# Candidate 1: Strong profile\n",
        "candidate1 = {\n",
        "    'age': 28,\n",
        "    'years_of_experience': 5,\n",
        "    'technical_test_score': 85,\n",
        "    'interview_score': 8.5,\n",
        "    'previous_employment': 1,  # Yes\n",
        "}\n",
        "# Add education encoding (Bachelor's degree)\n",
        "for col in X.columns:\n",
        "    if col.startswith('edu_'):\n",
        "        candidate1[col] = 1 if col == 'edu_Bachelor' else 0\n",
        "\n",
        "candidate1_df = pd.DataFrame([candidate1], columns=X.columns)\n",
        "pred1 = dt_classifier.predict(candidate1_df)[0]\n",
        "prob1 = dt_classifier.predict_proba(candidate1_df)[0]\n",
        "\n",
        "print(\"\\nCANDIDATE 1 - Strong Profile:\")\n",
        "print(f\"  Age: 28, Experience: 5 years, Education: Bachelor's\")\n",
        "print(f\"  Technical Score: 85/100, Interview: 8.5/10, Previous Employment: Yes\")\n",
        "print(f\"  → PREDICTION: {'SUITABLE' if pred1 == 1 else 'NOT SUITABLE'}\")\n",
        "print(f\"  → CONFIDENCE: {max(prob1)*100:.1f}%\")\n",
        "\n",
        "# Candidate 2: Weak profile\n",
        "candidate2 = {\n",
        "    'age': 35,\n",
        "    'years_of_experience': 2,\n",
        "    'technical_test_score': 55,\n",
        "    'interview_score': 5.0,\n",
        "    'previous_employment': 0,  # No\n",
        "}\n",
        "for col in X.columns:\n",
        "    if col.startswith('edu_'):\n",
        "        candidate2[col] = 1 if col == 'edu_High School' else 0\n",
        "\n",
        "candidate2_df = pd.DataFrame([candidate2], columns=X.columns)\n",
        "pred2 = dt_classifier.predict(candidate2_df)[0]\n",
        "prob2 = dt_classifier.predict_proba(candidate2_df)[0]\n",
        "\n",
        "print(\"\\nCANDIDATE 2 - Weak Profile:\")\n",
        "print(f\"  Age: 35, Experience: 2 years, Education: High School\")\n",
        "print(f\"  Technical Score: 55/100, Interview: 5.0/10, Previous Employment: No\")\n",
        "print(f\"  → PREDICTION: {'SUITABLE' if pred2 == 1 else 'NOT SUITABLE'}\")\n",
        "print(f\"  → CONFIDENCE: {max(prob2)*100:.1f}%\")\n",
        "\n",
        "# Candidate 3: Moderate profile\n",
        "candidate3 = {\n",
        "    'age': 30,\n",
        "    'years_of_experience': 7,\n",
        "    'technical_test_score': 72,\n",
        "    'interview_score': 7.0,\n",
        "    'previous_employment': 1,  # Yes\n",
        "}\n",
        "for col in X.columns:\n",
        "    if col.startswith('edu_'):\n",
        "        candidate3[col] = 1 if col == 'edu_Master' else 0\n",
        "\n",
        "candidate3_df = pd.DataFrame([candidate3], columns=X.columns)\n",
        "pred3 = dt_classifier.predict(candidate3_df)[0]\n",
        "prob3 = dt_classifier.predict_proba(candidate3_df)[0]\n",
        "\n",
        "print(\"\\nCANDIDATE 3 - Moderate Profile:\")\n",
        "print(f\"  Age: 30, Experience: 7 years, Education: Master's\")\n",
        "print(f\"  Technical Score: 72/100, Interview: 7.0/10, Previous Employment: Yes\")\n",
        "print(f\"  → PREDICTION: {'SUITABLE' if pred3 == 1 else 'NOT SUITABLE'}\")\n",
        "print(f\"  → CONFIDENCE: {max(prob3)*100:.1f}%\")\n",
        "\n",
        "# =============================================================================\n",
        "# TASK 6: MODEL EVALUATION\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"MODEL EVALUATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Accuracy Score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\n[1] ACCURACY SCORE: {accuracy*100:.2f}%\")\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(f\"\\n[2] CONFUSION MATRIX:\")\n",
        "print(cm)\n",
        "\n",
        "# Visualize Confusion Matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Not Suitable', 'Suitable'],\n",
        "            yticklabels=['Not Suitable', 'Suitable'])\n",
        "plt.title('Confusion Matrix', fontsize=14, pad=15)\n",
        "plt.ylabel('Actual', fontsize=12)\n",
        "plt.xlabel('Predicted', fontsize=12)\n",
        "plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
        "print(\"✓ Confusion matrix saved as 'confusion_matrix.png'\")\n",
        "\n",
        "# Classification Report\n",
        "print(f\"\\n[3] CLASSIFICATION REPORT:\")\n",
        "print(classification_report(y_test, y_pred,\n",
        "                          target_names=['Not Suitable', 'Suitable']))\n",
        "\n",
        "# =============================================================================\n",
        "# BONUS TASK: FEATURE IMPORTANCE ANALYSIS\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"BONUS: FEATURE IMPORTANCE ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Get feature importances\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Importance': dt_classifier.feature_importances_\n",
        "}).sort_values('Importance', ascending=False)\n",
        "\n",
        "print(\"\\n[1] FEATURE IMPORTANCE RANKING:\")\n",
        "print(feature_importance.to_string(index=False))\n",
        "\n",
        "# Visualize feature importance\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(feature_importance['Feature'][:10], feature_importance['Importance'][:10], color='steelblue')\n",
        "plt.xlabel('Importance Score', fontsize=12)\n",
        "plt.ylabel('Feature', fontsize=12)\n",
        "plt.title('Top 10 Most Important Features', fontsize=14, pad=15)\n",
        "plt.gca().invert_yaxis()\n",
        "plt.tight_layout()\n",
        "plt.savefig('feature_importance.png', dpi=300, bbox_inches='tight')\n",
        "print(\"\\n✓ Feature importance plot saved as 'feature_importance.png'\")\n",
        "\n",
        "# Summary\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ANALYSIS SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\n✓ Dataset processed: {df.shape[0]} samples, {df.shape[1]} features\")\n",
        "print(f\"✓ Model trained: Decision Tree Classifier\")\n",
        "print(f\"✓ Model accuracy: {accuracy*100:.2f}%\")\n",
        "print(f\"✓ Top 3 important features:\")\n",
        "for i in range(min(3, len(feature_importance))):\n",
        "    print(f\"   {i+1}. {feature_importance.iloc[i]['Feature']}: {feature_importance.iloc[i]['Importance']:.4f}\")\n",
        "print(\"\\n✓ All visualizations saved successfully!\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "\n"
      ]
    }
  ]
}